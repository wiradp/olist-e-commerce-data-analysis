{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a Pacmann Academy SQL & Data Wrangling project involving visual examination of datasets, problem identification, and problem solving. First, introduce the Olist company and the datasets. Olist is a Brazilian e-commerce company that provides solutions for online sales and e-commerce services. It offers a variety of technologies, tools, and connectors to help streamline and speed online business processes. Finally, provide remedies to the challenges and a benefit evaluation. The Python programming language is utilized in this project for data analysis and graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Number of Order per Each Product Category: Identifying the number of orders received by Olist in each product category helps in understanding the popularity of a particular product category.\n",
    "- The most item of product categories: Analyze the top product categories to understand the extent to which these products contribute to Olist's revenue and popularity.\n",
    "- Top 3 for Each Product Category Name by Product Category: Displays the top three products in each product category to provide insight into the most popular products in each category.\n",
    "- Top 10 Customer State Capacity: Identifying the ten states with the largest customer capacity helped Olist identify the most potential regions.\n",
    "- Revenue for Each State: Analyzing the revenue received by Olist from each state, helps in understanding the revenue contribution of each region.\n",
    "- Monthly Revenue: Identify Olist's monthly revenue trends to assist in financial planning and business growth.\n",
    "- Total Revenue per Each Product Category: Calculated the total revenue earned by each product category to estimate the relative contribution of each category.\n",
    "- The Relationship between the Price of the Product and the Payment Value: Analyze the relationship between product price and payment value to understand if any correlations or trends can be identified.\n",
    "- The Relationship between Product Volume and the Price: Analyze the relationship between product volume and price to evaluate whether product volume affects price.\n",
    "- Average Price over Time by Product Category: Understand the average change in product prices over time within each product category.\n",
    "- Payment Type Distribution: Display the distribution of payment types used by Olist customers to assist in better payment strategies.\n",
    "- Payment Installment: Analyze payments made in installments to identify term payment patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Stages\n",
    "1. Dataset\n",
    "    - Accessing dataset\n",
    "    - Load dataset\n",
    "    - Create dataframe\n",
    "2. Exploration and Processing\n",
    "    - NaN identification\n",
    "    - Outlier identification\n",
    "    - Identify inconsistent format\n",
    "    - Identify duplicate data\n",
    "    - Other checks required\n",
    "3. Explorating Data and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by following the steps above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Accessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite3 used to integrate SQLite database with Python\n",
    "import sqlite3\n",
    "\n",
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',100)  \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import MonthLocator, YearLocator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to load dataset\n",
    "\n",
    "def get_result(query): # Create the get_result function\n",
    "    dbfile = 'D:\\courses-pacmann\\project-datawrangling-sql\\Dataset\\olist.db' # Create file path\n",
    "    connection = sqlite3.connect(dbfile) # Accessing the dbfile\n",
    "    cursor = connection.cursor() # Create a cursor object to execute SQL commands on a database\n",
    "    cursor.execute(query) # Executing SQL commands\n",
    "    data = cursor.fetchall() # Retrieve the result of SQL commands\n",
    "    cursor.close() # Close the cursor\n",
    "    connection.close() # Close connection\n",
    "    return(data) # Return to the SQL command result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the names of tables and columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SQL commands to view tables in the olist database\n",
    "query_get_tables = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "\n",
    "# Run SQL command using get_result function\n",
    "tables = get_result(query_get_tables) # View tables in the dbfile\n",
    "\n",
    "# Show table names\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f'Table Name : {table_name}')\n",
    "\n",
    "    # Define the SQL command to get the column structure of the table\n",
    "    query_get_column = f'PRAGMA table_info({table_name});'\n",
    "\n",
    "    # Run SQL command using get_result function\n",
    "    columns = get_result(query_get_column)\n",
    "\n",
    "    # Display the names of the columns in the table\n",
    "    for column in columns:\n",
    "        column_name = column[1]\n",
    "        print(f' Column    : {column_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a dataframe\n",
    "def create_df(data, columns):\n",
    "    process_data  = pd.DataFrame(data=data, columns=columns).drop('index', axis=1)\n",
    "\n",
    "    # Reset column index\n",
    "    process_data = process_data.reset_index(drop=True)\n",
    "\n",
    "    # Combine multiple index levels to create a single column index\n",
    "    process_data.columns = [''.join(col).strip() for col in process_data.columns.values]\n",
    "\n",
    "    return process_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create columns for each tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates column variables for each table\n",
    "\n",
    "# Customer Column\n",
    "olist_customer_column = ['index','customer_id','customer_unique_id','customer_zip_code_prefix','customer_city','customer_state']\n",
    "\n",
    "# Order Column\n",
    "olist_order_column = ['index','order_id','customer_id','order_status','order_purchase_timestamp','order_approved_at',\n",
    "                      'order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date']\n",
    "\n",
    "# Order Review Column\n",
    "olist_order_reviews_column = ['index','review_id','order_id','review_score','review_comment_title','review_comment_message',\n",
    "                              'review_creation_date','review_answer_timestamp']\n",
    "\n",
    "# Order Payment Column\n",
    "olist_order_payments_column = ['index','order_id','payment_sequential','payment_type','payment_installments','payment_value']\n",
    "\n",
    "# Order Item Column\n",
    "olist_order_items_column = ['index','order_id','order_item_id','product_id','seller_id','shipping_limit_date','price','freight_value']\n",
    "\n",
    "# Product Column\n",
    "olist_products_column = ['index','product_id','product_category_name','product_name_lenght','product_description_lenght',\n",
    "                         'product_photos_qty','product_weight_g','product_length_cm','product_height_cm','product_width_cm']\n",
    "\n",
    "# Seller Column\n",
    "olist_sellers_column = ['index','seller_id','seller_zip_code_prefix','seller_city','seller_state']\n",
    "\n",
    "# Geolocation Column\n",
    "olist_geolocation_column = ['index','geolocation_zip_code_prefix','geolocation_lat','geolocation_lng',\n",
    "                            'geolocation_city','geolocation_state']\n",
    "\n",
    "# Product Category Column\n",
    "olist_product_category_column = ['index','product_category_name','product_category_name_english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retrieve all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df Customer\n",
    "olist_customer = create_df(get_result('SELECT * FROM olist_order_customer_dataset'),olist_customer_column)\n",
    "\n",
    "# Create df Order\n",
    "olist_order = create_df(get_result('SELECT * FROM olist_order_dataset'),olist_order_column)\n",
    "\n",
    "# Create df Order Review\n",
    "olist_order_reviews = create_df(get_result('SELECT * FROM olist_order_reviews_dataset'),olist_order_reviews_column)\n",
    "\n",
    "# Create df Order Paayment\n",
    "olist_order_payment = create_df(get_result('SELECT * FROM olist_order_payments_dataset'),olist_order_payments_column)\n",
    "\n",
    "# Create df Order Item\n",
    "olist_order_items = create_df(get_result('SELECT * FROM olist_order_items_dataset'),olist_order_items_column)\n",
    "\n",
    "# Create df Product\n",
    "olist_products = create_df(get_result('SELECT * FROM olist_products_dataset'),olist_products_column)\n",
    "\n",
    "# Create df Seller\n",
    "olist_sellers = create_df(get_result('SELECT * FROM olist_sellers_dataset'),olist_sellers_column)\n",
    "\n",
    "# Create df Geolocation\n",
    "olist_geolocation = create_df(get_result('SELECT * FROM olist_geolocation_dataset'),olist_geolocation_column)\n",
    "\n",
    "# Create df Product Category\n",
    "olist_product_category = create_df(get_result('SELECT * FROM product_category_name_translation'),olist_product_category_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge the necessary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the necessary tables\n",
    "df_olist = pd.merge(olist_customer, olist_order, on='customer_id', how='inner')\n",
    "df_olist = df_olist.merge(olist_order_payment, on='order_id', how=\"inner\")\n",
    "df_olist = df_olist.merge(olist_order_items, on='order_id', how=\"inner\")\n",
    "df_olist = df_olist.merge(olist_products, on='product_id', how=\"inner\")\n",
    "df_olist = df_olist.merge(olist_product_category, on='product_category_name', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of df_olist dataframe\n",
    "# df_olist_raw = df_olist.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classify product names into multiple product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique value at product_category_name_english column\n",
    "column_product_categories = df_olist['product_category_name_english'].unique()\n",
    "# for i in column_product_categories:\n",
    "#     print(i)\n",
    "print(column_product_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a product category classification function\n",
    "def classify_product(x):\n",
    "    categories = {\n",
    "        'Beauty & Health': ['health_beauty','perfumery','diapers_and_hygiene'],\n",
    "        'Book & Stationary': ['stationery','books_general_interest','books_imported','books_technical'],\n",
    "        'Electronics': ['computers_accessories','auto','air_conditioning','telephony','watches_gifts','consoles_games',\n",
    "                        'electronics','small_appliances','small_appliances_home_oven_and_coffee','signaling_and_security',\n",
    "                        'musical_instruments','fixed_telephony','tablets_printing_image','computers','audio','security_and_services'],\n",
    "        'Entertainment': ['sports_leisure','toys','art','music','dvds_blu_ray','christmas_supplies','party_supplies','cine_photo',\n",
    "                        'cds_dvds_musicals','arts_and_craftmanship'],\n",
    "        'Fashion': ['baby','fashio_female_clothing','cool_stuff','fashion_bags_accessories','fashion_male_clothing','fashion_shoes',\n",
    "                    'fashion_underwear_beach','fashion_sport','fashion_childrens_clothes'],\n",
    "        'Food & Drinks': ['food_drink','drinks','food'],\n",
    "        'Furniture': ['office_furniture','home_confort','furniture_decor','bed_bath_table','kitchen_dining_laundry_garden_furniture',\n",
    "                    'home_construction','furniture_living_room','furniture_bedroom','furniture_mattress_and_upholstery','home_comfort_2'],\n",
    "        'Home & Garden': ['housewares','garden_tools','pet_shop','construction_tools_lights','luggage_accessories','home_appliances_2',\n",
    "                        'home_appliances','market_place','costruction_tools_garden','la_cuisine','flowers'],\n",
    "        'Industry & Construction': ['costruction_tools_tools','construction_tools_construction','industry_commerce_and_business',\n",
    "                                    'construction_tools_safety','agro_industry_and_commerce']\n",
    "                    }\n",
    "    for category, keywords in categories.items():\n",
    "        if x in keywords:\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "df_olist['product_category'] = df_olist['product_category_name_english'].apply(classify_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the value in each category\n",
    "df_olist['product_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview dataset\n",
    "df_olist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chect rows and columns\n",
    "row, columns = df_olist.shape\n",
    "\n",
    "print(f\"df_olist has {row} and {columns} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop unrelevan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns\n",
    "df_olist.drop(['customer_zip_code_prefix', 'customer_city', 'payment_sequential', 'order_item_id', 'shipping_limit_date',\n",
    "               'freight_value', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g','order_approved_at',\n",
    "               'order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','payment_sequential',\n",
    "               'product_category_name', 'order_status'],\n",
    "              axis=1, inplace=True)\n",
    "\n",
    "df_olist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NaN identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for total NaN values\n",
    "\n",
    "nan_value = df_olist.isna().sum()[df_olist.isna().sum() > 0]\n",
    "\n",
    "# Construct a dataframe consists of NaN count and NaN percentage from the dataset\n",
    "nan_df_olist = pd.DataFrame ({'NaN_count ': nan_value,'NaN_percentage' : nan_value/len(df_olist)*100}).sort_values(by='NaN_percentage', ascending=False)\n",
    "\n",
    "# Show the data\n",
    "nan_df_olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary showing how many NaN values are in the 'product_length_cm', 'product_height_cm', and 'product_width_cm' columns \n",
    "# for each product category 'product_category_name_english'\n",
    "nan_summary = pd.pivot_table(df_olist, index='product_category_name_english', \n",
    "                             values=['product_length_cm', 'product_height_cm', 'product_width_cm'], \n",
    "                             aggfunc=lambda x: x.isna().sum())\n",
    "\n",
    "# Filter rows with NaN values in columns 'product_length_cm', 'product_height_cm', and 'product_width_cm'\n",
    "# >0 is checks if the value in the 'product_length_cm','product_height_cm', and 'product_width_cm' column is greater than 0. \n",
    "# It returns a Series boolean that will be True if the value is greater than 0 and False otherwise.\n",
    "filtered_rows = nan_summary.loc[(nan_summary['product_length_cm'] > 0) | \n",
    "                                (nan_summary['product_height_cm'] > 0) | \n",
    "                                (nan_summary['product_width_cm'] > 0)]\n",
    "\n",
    "filtered_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode (most frequent value) for the columns 'product_length_cm', 'product_height_cm', and 'product_width_cm' \n",
    "# for the product category 'baby' only\n",
    "baby_mode = df_olist.loc[df_olist['product_category_name_english'] == 'baby']\n",
    "\n",
    "# Find the most frequently occurring value in the 'product_length_cm' column\n",
    "product_length_mode = baby_mode['product_length_cm'].mode()[0]\n",
    "\n",
    "# Find the most frequent value in the 'product_height_cm' column\n",
    "product_height_mode = baby_mode['product_height_cm'].mode()[0]\n",
    "\n",
    "# Look for the most frequently occurring value in the 'product_width_cm' column\n",
    "product_width_mode = baby_mode['product_width_cm'].mode()[0]\n",
    "\n",
    "# Show each mode values\n",
    "print(f'Product length modus : {product_length_mode}')\n",
    "print(f'Product height modus : {product_height_mode}')\n",
    "print(f'Product width modus  : {product_width_mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN value with each column's mode\n",
    "\n",
    "# Fill 'product_length_cm' with mode value\n",
    "df_olist['product_length_cm'].fillna(product_length_mode, inplace=True)\n",
    "\n",
    "# Fill 'product_height_cm' mode value\n",
    "df_olist['product_height_cm'].fillna(product_height_mode, inplace=True)\n",
    "\n",
    "# Fill 'product_width_cm' with mode value\n",
    "df_olist['product_width_cm'].fillna(product_width_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Product Volume Column\n",
    "df_olist['product_volume_cm3'] = df_olist['product_length_cm'] * df_olist['product_height_cm'] * df_olist['product_width_cm']\n",
    "\n",
    "df_olist['product_volume_cm3'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NaN values\n",
    "df_olist.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like there is no more NaN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns length, heigth and width\n",
    "df_olist.drop(['product_length_cm','product_height_cm','product_width_cm'], axis=1, inplace=True)\n",
    "\n",
    "# Show dataframe\n",
    "df_olist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Outlier identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive stastistic\n",
    "df_olist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the price column, it can be seen that the 75% data and the max data have a very large range. We can assume this is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of data price\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.histplot(df_olist['price'], bins=100, palette='Set2')\n",
    "plt.title('Distribution of data price')\n",
    "plt.xlabel('Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It can be seen that the scale of the x axis reaches 7000.\n",
    "- This happens because there is data whose value is close to 7000.\n",
    "- This can be validated by looking at the statistical description of the price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show in boxlot graph\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.boxplot(df_olist['price'])\n",
    "plt.title('Box Plot : Distribution of data price')\n",
    "plt.xlabel('Price')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive stastistic at column 'price'\n",
    "df_olist['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It can be seen that the maximum value of the price column is 6735\n",
    "- This number is very far compared to the Q3 value of 1349.\n",
    "- The data above Q3 has the potential to be an outlier\n",
    "- Let's assume there are indeed outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will determine a data is an outlier, if its value is greater than Q3 + 1.5 IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Outliers Detection'''\n",
    "# Calculate the upper and lower limits\n",
    "#IQR\n",
    "\n",
    "q1 = df_olist['price'].quantile(0.25)\n",
    "q3 = df_olist['price'].quantile(0.75)\n",
    "\n",
    "iqr = q3 - q1\n",
    "\n",
    "upper = q3 + 1.5*iqr\n",
    "lower = q1 - 1.5*iqr\n",
    "\n",
    "print(f\"Q1 : {q1}\")\n",
    "print(f\"Q3 : {q3}\")\n",
    "print(f\"IQR : {iqr}\")\n",
    "print(f\"Upper : {upper}\")\n",
    "print(f\"Lower : {lower}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data without outliers\n",
    "df_olist = df_olist[df_olist['price'] < upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validated outlier output\n",
    "df_olist['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It can be seen that Q3 and the maximum value are not far apart\n",
    "- Outliers have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of data price\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.histplot(df_olist['price'], bins=100)\n",
    "plt.title('Distribution of data price')\n",
    "plt.xlabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Identify inconsistent format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify inconsistent format in 'product_category_name_english'\n",
    "\n",
    "# Show the data\n",
    "df_olist['product_category_name_english'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a varialbe to replace inconsistent name\n",
    "replace_product_name = {'home_confort':'home_comfort', 'home_comfort_2':'home_comfort', 'home_appliances_2':'home_appliances'}\n",
    "\n",
    "# Replace it into dataframe\n",
    "df_olist['product_category_name_english'].replace(replace_product_name, inplace=True)\n",
    "\n",
    "df_olist['product_category_name_english'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate info of dataframe\n",
    "df_olist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique value in column order_purchase_timestamp \n",
    "df_olist['order_purchase_timestamp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above, it can be seen that the column does not match the representation of the data type of the column:\n",
    "- order_purchase_timestamp: Indicates the purchase timestamp - Because the value in this column begins with the year, we will change the yearfirst parameter in the to_datetime function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert order_purchase_timestamp\n",
    "df_olist['order_purchase_timestamp'] = pd.to_datetime(df_olist['order_purchase_timestamp'], errors='coerce', yearfirst=True)\n",
    "\n",
    "# Show data tanggal setelah di convert\n",
    "df_olist['order_purchase_timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Identify duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate data of dataframe\n",
    "df_olist[df_olist.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate data\n",
    "df_olist = df_olist.drop_duplicates(keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplication across DataFrames\n",
    "duplicate_df_olist = df_olist.duplicated(keep='first', subset=None)\n",
    "\n",
    "# Check if there is duplication in all DataFrames\n",
    "if duplicate_df_olist.any():\n",
    "    # There is data duplication\n",
    "    print(\"There is duplicate data in DataFrame df_olist\")\n",
    "    # Display rows that are duplicates\n",
    "    duplicate_rows = df_olist[duplicate_df_olist]\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    # No duplication of data\n",
    "    print(\"No data duplication in DataFrame df_olist\")\n",
    "\n",
    "df_olist[df_olist.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explorating Data and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Number of order per each product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data of product category with bar plots \n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.barplot(x=df_olist['product_category'].value_counts().values, y=df_olist['product_category'].value_counts().index, palette='Set2')\n",
    "plt.title('Number of order per each product category')\n",
    "max_values = df_olist.groupby('product_category')['product_category'].count().max()\n",
    "min_values = df_olist.groupby('product_category')['product_category'].count().min()\n",
    "for index, value in enumerate(df_olist['product_category'].value_counts().values):\n",
    "    if value == max_values:\n",
    "        ax.text(value, index, f'{value}', ha='right', va='center')\n",
    "    if value == min_values:\n",
    "        ax.text(value, index, f'{value}', ha='left', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electronics as the most ordered product category with 25033 orders and food & drinks as the least ordered product category with 1008 orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 The most item in product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter max value count in product category\n",
    "df_olist['product_category'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show item of product categories in Electronics\n",
    "\n",
    "# Filter DataFrame for product_category equal to \"Electronics\"\n",
    "electronic_df = df_olist[df_olist['product_category'] == 'Electronics']\n",
    "\n",
    "# Count the number of occurrences of each product_category_name_english\n",
    "category_count = electronic_df['product_category_name_english'].value_counts().reset_index()\n",
    "category_count.columns = ['product_category_name_english', 'count']\n",
    "\n",
    "# Sort DataFrame descendingly by its number\n",
    "category_count = category_count.sort_values(by='count', ascending=False)\n",
    "max_category_count = category_count['count'].max()\n",
    "\n",
    "\n",
    "# Visualize the data with bar plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x='count', y='product_category_name_english', data=category_count, palette='Set2')\n",
    "plt.title('Product Categories in Electronics')\n",
    "plt.ylabel('Product Category Name ')\n",
    "highest_count_category = category_count[category_count['count'] == max_category_count]['product_category_name_english'].values[0]\n",
    "ax.text(max_category_count, 0, f'{max_category_count}', ha='right', va='center', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product category's most ordered items, totaling 6740, are evidently computer accessories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Show top 3 for each product category name by product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped the data based on 'product_category' and 'product_category_name_english', then counted the number.\n",
    "category_counts = df_olist.groupby(['product_category', 'product_category_name_english']).size().reset_index(name='count')\n",
    "\n",
    "# Filtering the top 3 product_category_name_english in each product_category\n",
    "top_categories = category_counts.groupby('product_category').apply(lambda x: x.nlargest(3, 'count')).reset_index(drop=True)\n",
    "\n",
    "# Visualize for each product_category with bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_categories, x='count', y='product_category_name_english', hue='product_category', palette='Set2')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Product Category Name')\n",
    "plt.title('Top 3 Product Categories by Product Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health Beauty, Stationery, Computer accessories, Sport Leisure, Cool Stuff, Food, Bed Bath Table, Housewares, Construction tools construction are the most item ordered for each product category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Top 10 Customer state capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Top 10 customer state capacities\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.barplot(x=df_olist['customer_state'].value_counts().values[:10], y=df_olist['customer_state'].value_counts().index[:10], palette='Set2')\n",
    "plt.title('Top 10 Customer State Capacity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the state SP (São Paulo) is the country that makes the most orders of 41115. SP (São Paulo) state code can be found at (https://brazil-help.com/brazilian_states.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Revenue for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group state by payment value\n",
    "\n",
    "state_revenue = df_olist.groupby('customer_state')['payment_value'].sum().reset_index()\n",
    "\n",
    "# Sorting descending state revenue\n",
    "state_revenue = state_revenue.sort_values(by='payment_value', ascending=False)\n",
    "\n",
    "# Visualize state revenue with bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='customer_state', y='payment_value', data=state_revenue, palette='Set2')\n",
    "plt.title('Total Revenue per State')\n",
    "plt.xlabel('Customer State')\n",
    "plt.ylabel('Total Revenue (Million)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SP(São Paulo) is the state with the highest revenue of 4493263.20 and RR (Roraima) has the lowest revenue of 6678.50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Monthly Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract order_purchase_timestamp into order_month\n",
    "df_olist['order_month'] = df_olist['order_purchase_timestamp'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Groupby order_month by payment_value to get monthly revenue\n",
    "monthly_revenue = df_olist.groupby('order_month')['payment_value'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "sns.lineplot(x='order_month', y='payment_value', data=monthly_revenue)\n",
    "plt.title('Monthly Revenue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue (Million)')\n",
    "plt.xticks(rotation=45)  # Untuk memutar label sumbu x agar lebih mudah dibaca\n",
    "\n",
    "# Find the month with the highest revenue\n",
    "max_revenue_point = monthly_revenue.loc[monthly_revenue['payment_value'].idxmax()]\n",
    "min_revenue_point = monthly_revenue.loc[monthly_revenue['payment_value'].idxmin()]\n",
    "\n",
    "# Annotate the highest revenue point\n",
    "plt.annotate(f'Highest: {max_revenue_point[\"payment_value\"]:.2f}', \n",
    "             xy=(max_revenue_point['order_month'], max_revenue_point['payment_value']),\n",
    "             xytext=(max_revenue_point['order_month'], max_revenue_point['payment_value'] + 1000), \n",
    "             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "# Annotate the lowest revenue point\n",
    "plt.annotate(f'Lowest: {min_revenue_point[\"payment_value\"]:.2f}', \n",
    "             xy=(min_revenue_point['order_month'], min_revenue_point['payment_value']),\n",
    "             xytext=(min_revenue_point['order_month'], min_revenue_point['payment_value'] - 1000), \n",
    "             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that November 2017 had the largest revenue, totaling 879899.45, while December 2012 had the lowest revenue, totaling 19.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Total revenue per each product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby product_category with paymeny_value to get revenue product category\n",
    "revenue_product_cat = df_olist.groupby('product_category')['payment_value'].sum().reset_index()\n",
    "\n",
    "# Sorting descending revenue product category\n",
    "revenue_product_cat = revenue_product_cat.sort_values(by='payment_value', ascending=False)\n",
    "\n",
    "#Visualisize with barplot\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.barplot(x='product_category', y='payment_value', data=revenue_product_cat, palette='Set2')\n",
    "plt.title('Total Revenue Per Each Product Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Total Revenue (Million)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Food & Beverages has the lowest revenue at 82544.05, while electronics is the product category with the highest revenue at 2794148.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8 The relationship between the price of the product and the payment value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between the price of the product and the payment value.\n",
    "\n",
    "# Visualize with Scatter plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='price', y='payment_value', data=df_olist, color='green', alpha=0.5)\n",
    "plt.title('Price vs. Payment Value')\n",
    "plt.xlabel('Price (R$)')\n",
    "plt.ylabel('Payment Value')\n",
    "\n",
    "# Calculate the regression coefficient and intercept\n",
    "slope, intercept = np.polyfit(df_olist['price'], df_olist['payment_value'], 1)\n",
    "\n",
    "# Create an array of x-values for the linear trend line\n",
    "x = np.array([df_olist['price'].min(), df_olist['price'].max()])\n",
    "\n",
    "# Create an array of y-values for the linear trend line using the regression equation\n",
    "y = slope * x + intercept\n",
    "\n",
    "# Add a linear trend line to the plot\n",
    "plt.plot(x, y, color='red', linestyle='--', label=f'Trendline: y = {slope:.2f}x + {intercept:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive Relationship: This visualization shows that there is a positive relationship between \"price\" and \"payment_value,\" with the majority of the data points forming an upward pattern from left to right. Put another way, a product's payment value increases with its price.\n",
    "- Outliers: Outliers are data points that deviate significantly from the general pattern. These outliers are transactions or high-priced products with a considerably higher payout value than other products. This could be a sign of some exceptional products or huge purchases that result in larger payments than the price.\n",
    "- Data Concentration: The majority of the data points have relatively low price ranges and payment values. This shows that the majority of transactions involve the purchase of decently priced goods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.9 The relationship between Product Volume and the Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between Product Volume and the Price.\n",
    "\n",
    "# Visualize with Scatter plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='product_volume_cm3', y='price', data=df_olist, color='blue', alpha=0.5)\n",
    "plt.title('Scatter Plot Product Volume vs. Price')\n",
    "plt.xlabel('Product Volume (cm3)')\n",
    "plt.ylabel('Price (R$)')\n",
    "\n",
    "# Calculate the regression coefficient and intercept\n",
    "slope, intercept = np.polyfit(df_olist['product_volume_cm3'], df_olist['price'], 1)\n",
    "\n",
    "# Create an array of x-values for the linear trend line\n",
    "x = np.array([df_olist['product_volume_cm3'].min(), df_olist['product_volume_cm3'].max()])\n",
    "\n",
    "# Create an array of y-values for the linear trend line using the regression equation\n",
    "y = slope * x + intercept\n",
    "\n",
    "# Add a linear trend line to the plot\n",
    "plt.plot(x, y, color='red', linestyle='--', label=f'Trendline: y = {slope:.2f}x + {intercept:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive Relationship: This visualization shows that there is a positive relationship between \"product_volume_cm3\" and \"price\" with the majority of the data points forming an upward pattern from left to right. Put another way, a product volumes value increases with its price.\n",
    "- Data Concentration: The majority of the data points have relatively small product volume and price. This shows that the majority of transactions involve the purchase of decently priced goods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.10 Average Price over Time by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'order_month' and 'product_category' and calculate the mean 'price'\n",
    "avg_price = df_olist.groupby(['order_month', 'product_category'])['price'].mean().unstack()\n",
    "\n",
    "# Visualize with line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for category in avg_price.columns:\n",
    "    plt.plot(avg_price.index, avg_price[category], label=category)\n",
    "\n",
    "plt.title('Average Price Over Time by Product Category')\n",
    "plt.xlabel('Order Month')\n",
    "plt.ylabel('Average Price')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the average monthly price change for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.11 Payment Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(df_olist['payment_type'].value_counts().values, \n",
    "        autopct='%1.1f%%', \n",
    "        shadow=False, startangle=90,\n",
    "        labels=df_olist['payment_type'].value_counts().index)\n",
    "plt.title('Payment Type Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems obvious that the majority of customers (73.9%) pay with credit cards while placing orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.12 Payment Installement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olist['payment_installments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a value of 0 in the payment_installment column in the dataframe\n",
    "df_olist = df_olist[df_olist['payment_installments'] !=0 ]\n",
    "\n",
    "df_olist.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data with payment installment value 0\n",
    "null_payment_instalment = df_olist[df_olist['payment_installments'] == 0]\n",
    "\n",
    "null_payment_instalment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulisize payment installment with countplot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x=df_olist['payment_installments'], palette='Set2')\n",
    "plt.title('Payment Installement Distribution')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that the majority of clients (49997) pay by credit card in 1-month installments when placing an order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
